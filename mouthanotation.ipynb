{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pauljohn99/ML-learnings/blob/main/mouthanotation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AaLh-lBv_yky",
        "outputId": "f1a16793-2603-4336-95d2-dc90869976fe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'vision'...\n",
            "remote: Enumerating objects: 276027, done.\u001b[K\n",
            "remote: Counting objects: 100% (15228/15228), done.\u001b[K\n",
            "remote: Compressing objects: 100% (743/743), done.\u001b[K\n",
            "remote: Total 276027 (delta 14526), reused 15119 (delta 14455), pack-reused 260799\u001b[K\n",
            "Receiving objects: 100% (276027/276027), 552.51 MiB | 16.42 MiB/s, done.\n",
            "Resolving deltas: 100% (252295/252295), done.\n",
            "fatal: not a git repository (or any of the parent directories): .git\n"
          ]
        }
      ],
      "source": [
        "!pip install pycocotools --quiet\n",
        "!git clone https://github.com/pytorch/vision.git\n",
        "!git checkout v0.3.0\n",
        "!cp vision/references/detection/utils.py ./\n",
        "!cp vision/references/detection/transforms.py ./\n",
        "!cp vision/references/detection/coco_eval.py ./\n",
        "!cp vision/references/detection/engine.py ./\n",
        "!cp vision/references/detection/coco_utils.py ./"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qxfwMo4Aibw"
      },
      "outputs": [],
      "source": [
        "# Basic python and ML Libraries\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "# for ignoring warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# We will be reading images using OpenCV\n",
        "import cv2\n",
        "\n",
        "# xml library for parsing xml files\n",
        "from xml.etree import ElementTree as et\n",
        "\n",
        "# matplotlib for visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as patches\n",
        "\n",
        "# torchvision libraries\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms as torchtrans  \n",
        "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
        "\n",
        "# these are the helper libraries imported.\n",
        "from engine import train_one_epoch, evaluate\n",
        "import utils\n",
        "import transforms as T\n",
        "\n",
        "# for image augmentations\n",
        "import albumentations as A\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfUnYhWl1iAm",
        "outputId": "34d802c3-e2f0-46e3-df0a-8eca850957d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqE1ZIqKWoL7",
        "outputId": "81e794be-271f-4f98-8d8c-217ee1a00141"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of dataset =  100 \n",
            "\n",
            "(224, 224, 3) \n",
            " {'boxes': tensor([[ 75.7008,  96.2500, 164.7424, 121.9750]]), 'labels': tensor([1]), 'area': tensor([2290.5940]), 'iscrowd': tensor([0]), 'image_id': tensor([1])}\n"
          ]
        }
      ],
      "source": [
        "# defining the files directory and testing directory\n",
        "files_dir = '/content/drive/MyDrive/mouth-area-practice/training/images'\n",
        "test_dir = '/content/drive/MyDrive/mouth-area-practice/testing/images'\n",
        "\n",
        "\n",
        "class FruitImagesDataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, files_dir, width, height, transforms=None):\n",
        "        self.transforms = transforms\n",
        "        self.files_dir = files_dir\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        \n",
        "        # sorting the images for consistency\n",
        "        # To get images, the extension of the filename is checked to be jpg\n",
        "        self.imgs = [image for image in sorted(os.listdir(files_dir))\n",
        "                        if image[-4:]=='.jpg']\n",
        "        \n",
        "          \n",
        "        # classes: 0 index is reserved for background\n",
        "        self.classes = [_,'mouth']\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        img_name = self.imgs[idx]\n",
        "        image_path = os.path.join(self.files_dir, img_name)\n",
        "\n",
        "        # reading the images and converting them to correct size and color    \n",
        "        img = cv2.imread(image_path)\n",
        "       \n",
        "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        img_res = cv2.resize(img_rgb, (self.width, self.height), cv2.INTER_AREA)\n",
        "        # diving by 255\n",
        "        img_res /= 255.0\n",
        "        # annotation file\n",
        "        annot_filename = img_name[:-4] + '.xml'\n",
        "        annot_file_path = os.path.join(self.files_dir, annot_filename)\n",
        "        \n",
        "        boxes = []\n",
        "        labels = []\n",
        "        tree = et.parse(annot_file_path)\n",
        "        root = tree.getroot()\n",
        "        \n",
        "        # cv2 image gives size as height x width\n",
        "        wt = img.shape[1]\n",
        "        ht = img.shape[0]\n",
        "        \n",
        "        # box coordinates for xml files are extracted and corrected for image size given\n",
        "        for member in root.findall('object'):\n",
        "            labels.append(self.classes.index(member.find('name').text))\n",
        "            \n",
        "            # bounding box\n",
        "            xmin = int(member.find('bndbox').find('xmin').text)\n",
        "            xmax = int(member.find('bndbox').find('xmax').text)\n",
        "            \n",
        "            ymin = int(member.find('bndbox').find('ymin').text)\n",
        "            ymax = int(member.find('bndbox').find('ymax').text)\n",
        "            \n",
        "            \n",
        "            xmin_corr = (xmin/wt)*self.width\n",
        "            xmax_corr = (xmax/wt)*self.width\n",
        "            ymin_corr = (ymin/ht)*self.height\n",
        "            ymax_corr = (ymax/ht)*self.height\n",
        "            \n",
        "            boxes.append([xmin_corr, ymin_corr, xmax_corr, ymax_corr])\n",
        "        \n",
        "        # convert boxes into a torch.Tensor\n",
        "        boxes = torch.as_tensor(boxes, dtype=torch.float32)\n",
        "        \n",
        "        # getting the areas of the boxes\n",
        "        area = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
        "\n",
        "        # suppose all instances are not crowd\n",
        "        iscrowd = torch.zeros((boxes.shape[0],), dtype=torch.int64)\n",
        "        \n",
        "        labels = torch.as_tensor(labels, dtype=torch.int64)\n",
        "\n",
        "\n",
        "        target = {}\n",
        "        target[\"boxes\"] = boxes\n",
        "        target[\"labels\"] = labels\n",
        "        target[\"area\"] = area\n",
        "        target[\"iscrowd\"] = iscrowd\n",
        "        # image_id\n",
        "        image_id = torch.tensor([idx])\n",
        "        target[\"image_id\"] = image_id\n",
        "\n",
        "\n",
        "        if self.transforms:\n",
        "            \n",
        "            sample = self.transforms(image = img_res,\n",
        "                                     bboxes = target['boxes'],\n",
        "                                     labels = labels)\n",
        "            \n",
        "            img_res = sample['image']\n",
        "            target['boxes'] = torch.Tensor(sample['bboxes'])\n",
        "            \n",
        "            \n",
        "            \n",
        "        return img_res, target\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "\n",
        "# check dataset\n",
        "dataset = FruitImagesDataset(files_dir, 224, 224)\n",
        "print('length of dataset = ', len(dataset), '\\n')\n",
        "\n",
        "# getting the image and target for a test index.  Feel free to change the index.\n",
        "img, target = dataset[1]\n",
        "print(img.shape, '\\n',target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_6iCkaOrX32v"
      },
      "outputs": [],
      "source": [
        "# def plot_img_bbox(img, target):\n",
        "#     # plot the image and bboxes\n",
        "#     # Bounding boxes are defined as follows: x-min y-min width height\n",
        "#     fig, a = plt.subplots(1,1)\n",
        "#     fig.set_size_inches(5,5)\n",
        "#     a.imshow(img)\n",
        "#     for box in (target['boxes']):\n",
        "#         x, y, width, height  = box[0], box[1], box[2]-box[0], box[3]-box[1]\n",
        "#         rect = patches.Rectangle((x, y),\n",
        "#                                  width, height,\n",
        "#                                  linewidth = 2,\n",
        "#                                  edgecolor = 'g',\n",
        "#                                  facecolor = 'none')\n",
        "\n",
        "#         # Draw the bounding box on top of the image\n",
        "#         print(type(rect))\n",
        "#         a.add_patch(rect)\n",
        "#     plt.show()\n",
        "    \n",
        "# # plotting the image with bboxes. Feel free to change the index\n",
        "# img, target = dataset[0]\n",
        "# plot_img_bbox(img, target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcRSE5Vua458"
      },
      "outputs": [],
      "source": [
        "# def get_object_detection_model(num_classes):\n",
        "\n",
        "#     # load a model pre-trained pre-trained on COCO\n",
        "#     model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "    \n",
        "#     # get number of input features for the classifier\n",
        "#     in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
        "#     # replace the pre-trained head with a new one\n",
        "#     model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes) \n",
        "\n",
        "#     return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7qlnDCh2a-ey"
      },
      "outputs": [],
      "source": [
        "# Send train=True fro training transforms and False for val/test transforms\n",
        "def get_transform(train):\n",
        "    \n",
        "    if train:\n",
        "        return A.Compose([\n",
        "                            A.HorizontalFlip(0.5),\n",
        "                     # ToTensorV2 converts image to pytorch tensor without div by 255\n",
        "                            ToTensorV2(p=1.0) \n",
        "                        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})\n",
        "    else:\n",
        "        return A.Compose([\n",
        "                            ToTensorV2(p=1.0)\n",
        "                        ], bbox_params={'format': 'pascal_voc', 'label_fields': ['labels']})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "C30_3htPfHZa",
        "outputId": "ae3ae220-44ea-437c-cfa5-9294bffaa95f"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-f7f466c912d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# use our dataset and defined transformations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFruitImagesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFruitImagesDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m480\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# split the dataset in train and test set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'get_transform' is not defined"
          ]
        }
      ],
      "source": [
        "# use our dataset and defined transformations\n",
        "dataset = FruitImagesDataset(files_dir, 480, 480, transforms= get_transform(train=True))\n",
        "dataset_test = FruitImagesDataset(files_dir, 480, 480, transforms= get_transform(train=False))\n",
        "print(dataset)\n",
        "# split the dataset in train and test set\n",
        "torch.manual_seed(1)\n",
        "indices = torch.randperm(len(dataset)).tolist()\n",
        "\n",
        "# train test split\n",
        "test_split = 0.2\n",
        "tsize = int(len(dataset)*test_split)\n",
        "dataset = torch.utils.data.Subset(dataset, indices[:-tsize])\n",
        "dataset_test = torch.utils.data.Subset(dataset_test, indices[-tsize:])\n",
        "\n",
        "# define training and validation data loaders\n",
        "data_loader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=5, shuffle=True, num_workers=1,\n",
        "    collate_fn=utils.collate_fn)\n",
        "\n",
        "data_loader_test = torch.utils.data.DataLoader(\n",
        "    dataset_test, batch_size=3, shuffle=False, num_workers=0,\n",
        "    collate_fn=utils.collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iXx0ESw584Ps"
      },
      "outputs": [],
      "source": [
        "# # to train on gpu if selected.\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "\n",
        "# num_classes = 4\n",
        "\n",
        "# # get the model using our helper function\n",
        "# model = get_object_detection_model(num_classes)\n",
        "\n",
        "# # move model to the right device\n",
        "# model.to(device)\n",
        "\n",
        "# # construct an optimizer\n",
        "# params = [p for p in model.parameters() if p.requires_grad]\n",
        "# optimizer = torch.optim.SGD(params, lr=0.005,\n",
        "#                             momentum=0.9, weight_decay=0.0005)\n",
        "\n",
        "# # and a learning rate scheduler which decreases the learning rate by\n",
        "# # 10x every 3 epochs\n",
        "# lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n",
        "#                                                step_size=3,\n",
        "#                                                gamma=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CXNWGVxC8-nT",
        "outputId": "7553dbbf-23aa-4cb1-9b7a-1528dd12d35e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: [0]  [ 0/16]  eta: 0:22:40  lr: 0.000002  loss: 0.2547 (0.2547)  loss_classifier: 0.0974 (0.0974)  loss_box_reg: 0.1322 (0.1322)  loss_objectness: 0.0200 (0.0200)  loss_rpn_box_reg: 0.0051 (0.0051)  time: 85.0347  data: 0.5771\n",
            "Epoch: [0]  [10/16]  eta: 0:07:32  lr: 0.000025  loss: 0.2330 (0.2177)  loss_classifier: 0.0952 (0.0930)  loss_box_reg: 0.1133 (0.1060)  loss_objectness: 0.0121 (0.0131)  loss_rpn_box_reg: 0.0054 (0.0056)  time: 75.4859  data: 0.0651\n",
            "Epoch: [0]  [15/16]  eta: 0:01:15  lr: 0.000034  loss: 0.2330 (0.2218)  loss_classifier: 0.0952 (0.0945)  loss_box_reg: 0.1133 (0.1084)  loss_objectness: 0.0118 (0.0135)  loss_rpn_box_reg: 0.0044 (0.0054)  time: 75.2690  data: 0.0493\n",
            "Epoch: [0] Total time: 0:20:04 (75.2707 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:59  model_time: 16.9739 (16.9739)  evaluator_time: 0.0016 (0.0016)  time: 17.0596  data: 0.0840\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.8896 (16.1078)  evaluator_time: 0.0023 (0.0024)  time: 16.2158  data: 0.1054\n",
            "Test: Total time: 0:01:53 (16.2161 s / it)\n",
            "Averaged stats: model_time: 16.8896 (16.1078)  evaluator_time: 0.0023 (0.0024)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.191\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.561\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.038\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.311\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.210\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.425\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.425\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.400\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.431\n",
            "Epoch: [1]  [ 0/16]  eta: 0:20:38  lr: 0.000034  loss: 0.1924 (0.1924)  loss_classifier: 0.0832 (0.0832)  loss_box_reg: 0.0988 (0.0988)  loss_objectness: 0.0062 (0.0062)  loss_rpn_box_reg: 0.0042 (0.0042)  time: 77.4194  data: 0.3120\n",
            "Epoch: [1]  [10/16]  eta: 0:07:25  lr: 0.000034  loss: 0.2354 (0.2234)  loss_classifier: 0.0956 (0.0951)  loss_box_reg: 0.1086 (0.1100)  loss_objectness: 0.0120 (0.0129)  loss_rpn_box_reg: 0.0047 (0.0055)  time: 74.2792  data: 0.0403\n",
            "Epoch: [1]  [15/16]  eta: 0:01:14  lr: 0.000034  loss: 0.2116 (0.2176)  loss_classifier: 0.0914 (0.0923)  loss_box_reg: 0.1046 (0.1071)  loss_objectness: 0.0118 (0.0129)  loss_rpn_box_reg: 0.0047 (0.0053)  time: 74.3978  data: 0.0320\n",
            "Epoch: [1] Total time: 0:19:50 (74.3998 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:58  model_time: 16.8182 (16.8182)  evaluator_time: 0.0016 (0.0016)  time: 16.9045  data: 0.0847\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.8443 (16.0618)  evaluator_time: 0.0023 (0.0027)  time: 16.1707  data: 0.1060\n",
            "Test: Total time: 0:01:53 (16.1710 s / it)\n",
            "Averaged stats: model_time: 16.8443 (16.0618)  evaluator_time: 0.0023 (0.0027)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.182\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.543\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.039\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.241\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.183\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.225\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.395\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.300\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.419\n",
            "Epoch: [2]  [ 0/16]  eta: 0:21:01  lr: 0.000034  loss: 0.1968 (0.1968)  loss_classifier: 0.0781 (0.0781)  loss_box_reg: 0.1012 (0.1012)  loss_objectness: 0.0151 (0.0151)  loss_rpn_box_reg: 0.0023 (0.0023)  time: 78.8600  data: 0.7573\n",
            "Epoch: [2]  [10/16]  eta: 0:07:29  lr: 0.000034  loss: 0.2201 (0.2199)  loss_classifier: 0.0968 (0.0918)  loss_box_reg: 0.1139 (0.1101)  loss_objectness: 0.0120 (0.0124)  loss_rpn_box_reg: 0.0058 (0.0056)  time: 74.9041  data: 0.0804\n",
            "Epoch: [2]  [15/16]  eta: 0:01:15  lr: 0.000034  loss: 0.2196 (0.2156)  loss_classifier: 0.0952 (0.0905)  loss_box_reg: 0.1114 (0.1070)  loss_objectness: 0.0108 (0.0127)  loss_rpn_box_reg: 0.0051 (0.0053)  time: 75.0288  data: 0.0592\n",
            "Epoch: [2] Total time: 0:20:00 (75.0313 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:59  model_time: 17.0132 (17.0132)  evaluator_time: 0.0019 (0.0019)  time: 17.1106  data: 0.0955\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.8969 (16.1596)  evaluator_time: 0.0025 (0.0026)  time: 16.2708  data: 0.1084\n",
            "Test: Total time: 0:01:53 (16.2711 s / it)\n",
            "Averaged stats: model_time: 16.8969 (16.1596)  evaluator_time: 0.0025 (0.0026)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.189\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.555\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.047\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.185\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            "Epoch: [3]  [ 0/16]  eta: 0:21:11  lr: 0.000003  loss: 0.2307 (0.2307)  loss_classifier: 0.0937 (0.0937)  loss_box_reg: 0.1160 (0.1160)  loss_objectness: 0.0096 (0.0096)  loss_rpn_box_reg: 0.0114 (0.0114)  time: 79.4921  data: 0.6208\n",
            "Epoch: [3]  [10/16]  eta: 0:07:31  lr: 0.000003  loss: 0.2156 (0.2113)  loss_classifier: 0.0917 (0.0895)  loss_box_reg: 0.1077 (0.1044)  loss_objectness: 0.0126 (0.0122)  loss_rpn_box_reg: 0.0044 (0.0053)  time: 75.1718  data: 0.0687\n",
            "Epoch: [3]  [15/16]  eta: 0:01:14  lr: 0.000003  loss: 0.2146 (0.2135)  loss_classifier: 0.0880 (0.0896)  loss_box_reg: 0.1087 (0.1070)  loss_objectness: 0.0118 (0.0116)  loss_rpn_box_reg: 0.0051 (0.0053)  time: 74.8972  data: 0.0516\n",
            "Epoch: [3] Total time: 0:19:58 (74.9001 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:58  model_time: 16.8496 (16.8496)  evaluator_time: 0.0018 (0.0018)  time: 16.9321  data: 0.0806\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.8772 (16.2935)  evaluator_time: 0.0025 (0.0026)  time: 16.4015  data: 0.1052\n",
            "Test: Total time: 0:01:54 (16.4016 s / it)\n",
            "Averaged stats: model_time: 16.8772 (16.2935)  evaluator_time: 0.0025 (0.0026)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.563\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            "Epoch: [4]  [ 0/16]  eta: 0:21:02  lr: 0.000003  loss: 0.2130 (0.2130)  loss_classifier: 0.0981 (0.0981)  loss_box_reg: 0.0967 (0.0967)  loss_objectness: 0.0093 (0.0093)  loss_rpn_box_reg: 0.0089 (0.0089)  time: 78.8796  data: 0.2523\n",
            "Epoch: [4]  [10/16]  eta: 0:07:30  lr: 0.000003  loss: 0.2203 (0.2210)  loss_classifier: 0.0940 (0.0916)  loss_box_reg: 0.1127 (0.1124)  loss_objectness: 0.0093 (0.0113)  loss_rpn_box_reg: 0.0061 (0.0057)  time: 75.1019  data: 0.0346\n",
            "Epoch: [4]  [15/16]  eta: 0:01:14  lr: 0.000003  loss: 0.2147 (0.2121)  loss_classifier: 0.0921 (0.0892)  loss_box_reg: 0.1116 (0.1065)  loss_objectness: 0.0093 (0.0111)  loss_rpn_box_reg: 0.0043 (0.0053)  time: 74.7559  data: 0.0286\n",
            "Epoch: [4] Total time: 0:19:56 (74.7589 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:58  model_time: 16.8378 (16.8378)  evaluator_time: 0.0019 (0.0019)  time: 16.9301  data: 0.0903\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.8171 (16.1830)  evaluator_time: 0.0026 (0.0030)  time: 16.2934  data: 0.1071\n",
            "Test: Total time: 0:01:54 (16.2937 s / it)\n",
            "Averaged stats: model_time: 16.8171 (16.1830)  evaluator_time: 0.0026 (0.0030)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.192\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.563\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.049\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.190\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            "Epoch: [5]  [ 0/16]  eta: 0:22:15  lr: 0.000003  loss: 0.2192 (0.2192)  loss_classifier: 0.0922 (0.0922)  loss_box_reg: 0.1069 (0.1069)  loss_objectness: 0.0155 (0.0155)  loss_rpn_box_reg: 0.0047 (0.0047)  time: 83.4598  data: 0.4838\n",
            "Epoch: [5]  [10/16]  eta: 0:07:33  lr: 0.000003  loss: 0.2091 (0.2089)  loss_classifier: 0.0876 (0.0874)  loss_box_reg: 0.1043 (0.1038)  loss_objectness: 0.0119 (0.0127)  loss_rpn_box_reg: 0.0047 (0.0050)  time: 75.5306  data: 0.0576\n",
            "Epoch: [5]  [15/16]  eta: 0:01:14  lr: 0.000003  loss: 0.2099 (0.2161)  loss_classifier: 0.0864 (0.0891)  loss_box_reg: 0.1043 (0.1066)  loss_objectness: 0.0149 (0.0152)  loss_rpn_box_reg: 0.0051 (0.0053)  time: 74.9483  data: 0.0436\n",
            "Epoch: [5] Total time: 0:19:59 (74.9529 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:58  model_time: 16.8030 (16.8030)  evaluator_time: 0.0018 (0.0018)  time: 16.8908  data: 0.0859\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.8666 (16.8409)  evaluator_time: 0.0025 (0.0027)  time: 16.9495  data: 0.1057\n",
            "Test: Total time: 0:01:58 (16.9498 s / it)\n",
            "Averaged stats: model_time: 16.8666 (16.8409)  evaluator_time: 0.0025 (0.0027)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.564\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            "Epoch: [6]  [ 0/16]  eta: 0:20:52  lr: 0.000000  loss: 0.2618 (0.2618)  loss_classifier: 0.1107 (0.1107)  loss_box_reg: 0.1336 (0.1336)  loss_objectness: 0.0112 (0.0112)  loss_rpn_box_reg: 0.0063 (0.0063)  time: 78.2944  data: 0.3020\n",
            "Epoch: [6]  [10/16]  eta: 0:07:26  lr: 0.000000  loss: 0.2214 (0.2166)  loss_classifier: 0.0909 (0.0910)  loss_box_reg: 0.1163 (0.1083)  loss_objectness: 0.0132 (0.0128)  loss_rpn_box_reg: 0.0044 (0.0046)  time: 74.4184  data: 0.0408\n",
            "Epoch: [6]  [15/16]  eta: 0:01:14  lr: 0.000000  loss: 0.2160 (0.2153)  loss_classifier: 0.0873 (0.0893)  loss_box_reg: 0.1059 (0.1072)  loss_objectness: 0.0128 (0.0135)  loss_rpn_box_reg: 0.0051 (0.0053)  time: 74.3897  data: 0.0322\n",
            "Epoch: [6] Total time: 0:19:50 (74.3915 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:58  model_time: 16.8222 (16.8222)  evaluator_time: 0.0019 (0.0019)  time: 16.9109  data: 0.0867\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.7348 (16.2475)  evaluator_time: 0.0026 (0.0032)  time: 16.3592  data: 0.1082\n",
            "Test: Total time: 0:01:54 (16.3594 s / it)\n",
            "Averaged stats: model_time: 16.7348 (16.2475)  evaluator_time: 0.0026 (0.0032)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.564\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            "Epoch: [7]  [ 0/16]  eta: 0:20:50  lr: 0.000000  loss: 0.2175 (0.2175)  loss_classifier: 0.0940 (0.0940)  loss_box_reg: 0.1068 (0.1068)  loss_objectness: 0.0087 (0.0087)  loss_rpn_box_reg: 0.0080 (0.0080)  time: 78.1393  data: 0.3271\n",
            "Epoch: [7]  [10/16]  eta: 0:07:29  lr: 0.000000  loss: 0.2289 (0.2126)  loss_classifier: 0.0954 (0.0898)  loss_box_reg: 0.1136 (0.1062)  loss_objectness: 0.0117 (0.0125)  loss_rpn_box_reg: 0.0037 (0.0042)  time: 74.8375  data: 0.0411\n",
            "Epoch: [7]  [15/16]  eta: 0:01:14  lr: 0.000000  loss: 0.2283 (0.2158)  loss_classifier: 0.0940 (0.0894)  loss_box_reg: 0.1097 (0.1071)  loss_objectness: 0.0139 (0.0140)  loss_rpn_box_reg: 0.0047 (0.0053)  time: 74.6895  data: 0.0323\n",
            "Epoch: [7] Total time: 0:19:55 (74.6913 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:59  model_time: 16.9562 (16.9562)  evaluator_time: 0.0018 (0.0018)  time: 17.0430  data: 0.0848\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.9575 (16.3542)  evaluator_time: 0.0025 (0.0026)  time: 16.4653  data: 0.1082\n",
            "Test: Total time: 0:01:55 (16.4654 s / it)\n",
            "Averaged stats: model_time: 16.9575 (16.3542)  evaluator_time: 0.0025 (0.0026)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.564\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            "Epoch: [8]  [ 0/16]  eta: 0:20:58  lr: 0.000000  loss: 0.1813 (0.1813)  loss_classifier: 0.0799 (0.0799)  loss_box_reg: 0.0903 (0.0903)  loss_objectness: 0.0065 (0.0065)  loss_rpn_box_reg: 0.0046 (0.0046)  time: 78.6456  data: 0.8645\n",
            "Epoch: [8]  [10/16]  eta: 0:07:27  lr: 0.000000  loss: 0.2049 (0.2103)  loss_classifier: 0.0871 (0.0889)  loss_box_reg: 0.0960 (0.1049)  loss_objectness: 0.0091 (0.0110)  loss_rpn_box_reg: 0.0050 (0.0054)  time: 74.6644  data: 0.0906\n",
            "Epoch: [8]  [15/16]  eta: 0:01:14  lr: 0.000000  loss: 0.2092 (0.2131)  loss_classifier: 0.0871 (0.0893)  loss_box_reg: 0.0970 (0.1071)  loss_objectness: 0.0091 (0.0114)  loss_rpn_box_reg: 0.0046 (0.0053)  time: 74.5316  data: 0.0661\n",
            "Epoch: [8] Total time: 0:19:52 (74.5344 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:58  model_time: 16.8479 (16.8479)  evaluator_time: 0.0021 (0.0021)  time: 16.9414  data: 0.0913\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.8008 (16.1993)  evaluator_time: 0.0025 (0.0027)  time: 16.3101  data: 0.1079\n",
            "Test: Total time: 0:01:54 (16.3104 s / it)\n",
            "Averaged stats: model_time: 16.8008 (16.1993)  evaluator_time: 0.0025 (0.0027)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.564\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n",
            "Epoch: [9]  [ 0/16]  eta: 0:20:55  lr: 0.000000  loss: 0.1756 (0.1756)  loss_classifier: 0.0818 (0.0818)  loss_box_reg: 0.0818 (0.0818)  loss_objectness: 0.0066 (0.0066)  loss_rpn_box_reg: 0.0055 (0.0055)  time: 78.4773  data: 0.2361\n",
            "Epoch: [9]  [10/16]  eta: 0:07:28  lr: 0.000000  loss: 0.2033 (0.2081)  loss_classifier: 0.0857 (0.0858)  loss_box_reg: 0.1029 (0.1056)  loss_objectness: 0.0104 (0.0113)  loss_rpn_box_reg: 0.0052 (0.0054)  time: 74.7960  data: 0.0348\n",
            "Epoch: [9]  [15/16]  eta: 0:01:14  lr: 0.000000  loss: 0.2170 (0.2125)  loss_classifier: 0.0882 (0.0891)  loss_box_reg: 0.1079 (0.1071)  loss_objectness: 0.0093 (0.0110)  loss_rpn_box_reg: 0.0052 (0.0053)  time: 74.7793  data: 0.0276\n",
            "Epoch: [9] Total time: 0:19:56 (74.7812 s / it)\n",
            "creating index...\n",
            "index created!\n",
            "Test:  [0/7]  eta: 0:01:59  model_time: 16.9196 (16.9196)  evaluator_time: 0.0020 (0.0020)  time: 17.0059  data: 0.0842\n",
            "Test:  [6/7]  eta: 0:00:16  model_time: 16.8042 (16.0542)  evaluator_time: 0.0025 (0.0026)  time: 16.1620  data: 0.1049\n",
            "Test: Total time: 0:01:53 (16.1622 s / it)\n",
            "Averaged stats: model_time: 16.8042 (16.0542)  evaluator_time: 0.0025 (0.0026)\n",
            "Accumulating evaluation results...\n",
            "DONE (t=0.01s).\n",
            "IoU metric: bbox\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.193\n",
            " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.564\n",
            " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.050\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.309\n",
            " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.191\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.235\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.455\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = -1.000\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.575\n",
            " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.425\n"
          ]
        }
      ],
      "source": [
        "# num_epochs = 10\n",
        "\n",
        "# for epoch in range(num_epochs):\n",
        "#     # training for one epoch\n",
        "#     train_one_epoch(model, optimizer, data_loader, device, epoch, print_freq=10)\n",
        "#     # update the learning rate\n",
        "#     lr_scheduler.step()\n",
        "#     # evaluate on the test dataset\n",
        "#     evaluate(model, data_loader_test, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDgQAp4fWsvS"
      },
      "outputs": [],
      "source": [
        "# the function takes the original prediction and the iou threshold.\n",
        "\n",
        "def apply_nms(orig_prediction, iou_thresh=0.3):\n",
        "    \n",
        "    # torchvision returns the indices of the bboxes to keep\n",
        "    keep = torchvision.ops.nms(orig_prediction['boxes'], orig_prediction['scores'], iou_thresh)\n",
        "    \n",
        "    final_prediction = orig_prediction\n",
        "    final_prediction['boxes'] = final_prediction['boxes'][keep]\n",
        "    final_prediction['scores'] = final_prediction['scores'][keep]\n",
        "    final_prediction['labels'] = final_prediction['labels'][keep]\n",
        "    \n",
        "    return final_prediction\n",
        "\n",
        "# function to convert a torchtensor back to PIL image\n",
        "def torch_to_pil(img):\n",
        "    return torchtrans.ToPILImage()(img).convert('RGB')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPn7FKnFeTFs"
      },
      "outputs": [],
      "source": [
        "model = torch.load(/content/mouth_model.pt)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SuH3ptz1WwNo"
      },
      "outputs": [],
      "source": [
        "# pick one image from the test set\n",
        "img, target = dataset_test[1]\n",
        "# put the model in evaluation mode\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    prediction = model([img.to(device)])[0]\n",
        "    \n",
        "print('predicted #boxes: ', len(prediction['labels']))\n",
        "print('real #boxes: ', len(target['labels']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dyc759NpWz83"
      },
      "outputs": [],
      "source": [
        "print('EXPECTED OUTPUT')\n",
        "print(target)\n",
        "plot_img_bbox(torch_to_pil(img), target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LpjL3ml4W2wP"
      },
      "outputs": [],
      "source": [
        "print('MODEL OUTPUT')\n",
        "print(prediction['boxes'].detach().cpu().numpy())\n",
        "pred=prediction['boxes'].detach().cpu()\n",
        "pred1={'boxes':pred}\n",
        "# prediction['boxes'].detach().cpu()\n",
        "# print(prediction['boxes'][1])\n",
        "print(pred1)\n",
        "out = torch_to_pil(img)\n",
        "plot_img_bbox(out,pred1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oh_CV2QEM-Rf"
      },
      "outputs": [],
      "source": [
        "nms_prediction = apply_nms(prediction, iou_thresh=0.1)\n",
        "print(prediction)\n",
        "pred=nms_prediction['boxes'].detach().cpu()\n",
        "pred1={'boxes':pred}\n",
        "print(pred1)\n",
        "print('NMS APPLIED MODEL OUTPUT')\n",
        "plot_img_bbox(torch_to_pil(img),pred1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rKwwzocUW7xY"
      },
      "outputs": [],
      "source": [
        "nms_prediction = apply_nms(prediction, iou_thresh=0.2)\n",
        "print(nms_prediction)\n",
        "\n",
        "print(nms_prediction['scores'])\n",
        "print(nms_prediction['scores'].detach().cpu().numpy())\n",
        "p=nms_prediction['scores'].detach().cpu().numpy()\n",
        "pr=np.argmax(p)\n",
        "print(pr)\n",
        "pred=np.reshape(nms_prediction['boxes'][pr].detach().cpu().numpy(), (-1, 4))\n",
        "print(type(pred))\n",
        "pred1={'boxes': pred}\n",
        "print(pred1)\n",
        "print('NMS APPLIED MODEL OUTPUT')\n",
        "plot_img_bbox(torch_to_pil(img),pred1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "20elJ5o4W_LA"
      },
      "outputs": [],
      "source": [
        "test_dataset = FruitImagesDataset(test_dir, 480, 480, transforms= get_transform(train=True))\n",
        "# pick one image from the test set\n",
        "y=len(test_dataset)\n",
        "for i in range(y):\n",
        " img, target = test_dataset[i]\n",
        " # put the model in evaluation mode\n",
        " model.eval()\n",
        " with torch.no_grad():\n",
        "    prediction = model([img.to(device)])[0]\n",
        " i=i+1  \n",
        "#  print('EXPECTED OUTPUT\\n')\n",
        "#  plot_img_bbox(torch_to_pil(img), target)\n",
        " print('MODEL OUTPUT\\n')\n",
        " nms_prediction = apply_nms(prediction, iou_thresh=0.1)\n",
        "#  print(nms_prediction['scores'])\n",
        "#  print(nms_prediction['scores'].detach().cpu().numpy())\n",
        " p=nms_prediction['scores'].detach().cpu().numpy()\n",
        " pr=np.argmax(p)\n",
        " x=max(p)\n",
        " print(x)\n",
        " pred=np.reshape(nms_prediction['boxes'][pr].detach().cpu().numpy(), (-1, 4))\n",
        "# print(type(pred))\n",
        " pred1={'boxes': pred}\n",
        "# print(pred1)\n",
        " print('NMS APPLIED MODEL OUTPUT')\n",
        " plot_img_bbox(torch_to_pil(img), pred1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vj7RLszkhaQF"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy\n",
        "from sklearn import metrics\n",
        "\n",
        "pred=target['boxes'].detach().cpu().numpy()\n",
        "print(pred[0])\n",
        "pred1=pred[0]\n",
        "# pred1={'boxes':pred}\n",
        "# print(pred1)\n",
        "# pred2=pred1['boxes'].detach().cpu().numpy()\n",
        "# print(pred2)\n",
        "\n",
        "p=nms_prediction['scores'].detach().cpu().numpy()\n",
        "pr=np.argmax(p)\n",
        "print(pr)\n",
        "pred3=nms_prediction['boxes'][pr].detach().cpu().numpy()\n",
        "print(pred3)\n",
        "# preds={'boxes': pred1}\n",
        "# print(preds)\n",
        "\n",
        "\n",
        "confusion_matrix = metrics.confusion_matrix(pred1, pred3)\n",
        "\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [False, True])\n",
        "\n",
        "cm_display.plot()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0kKRL5NvAAc3vauXF29HZ",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}